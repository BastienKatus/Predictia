{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85d5d45f-e50c-4c5d-b2dc-74a14373b0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: imblearn in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imblearn) (0.12.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.26.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\faycal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas scikit-learn tensorflow imblearn openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe0a39f1-95af-4009-8c6c-e96e3386adb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['appearances', 'club_games', 'clubs', 'competitions', 'game_events', 'game_lineups', 'games', 'player_valuations', 'players', 'clubs_link_api'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importation des librairies communes (peu prendre du temps)\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#Chemin menant aux données\n",
    "data_path = os.path.join(os.getcwd(), \"source\")\n",
    "#création du dictionnaire\n",
    "data_dict = dict()\n",
    "# Boucle pour récupérer tous les fichiers CSV dans le dossier et les ajouter au dictionnaire\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_path, file)\n",
    "        dict_key = file.split('.')[0]  # Nom du fichier sans l'extension .csv\n",
    "        data_dict[dict_key] = pd.read_csv(file_path)\n",
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2be59442-18ef-46a7-8e80-a1625f953b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toutes les fonctions\n",
    "def games_of_the_season(df_games, club_id, saison, lieu='tous'):\n",
    "    \"\"\"\n",
    "    Récupère tous les matchs d'une saison pour un club spécifié, ou les 10 derniers matchs si moins de 5 matchs dans la saison.\n",
    "    \n",
    "    Paramètres:\n",
    "    df_games (DataFrame) : DataFrame des matchs.\n",
    "    club_id (int) : ID du club.\n",
    "    saison (str) : Saison à filtrer.\n",
    "    lieu (str) : 'domicile', 'exterieur', ou 'tous' pour filtrer les matchs.\n",
    "    \n",
    "    Retourne:\n",
    "    DataFrame : Les matchs demandés avec les informations détaillées.\n",
    "    \"\"\"\n",
    "    # Filtrage initial par saison et lieu\n",
    "    if lieu == 'domicile':\n",
    "        matchs_du_club = df_games[(df_games['home_club_id'] == club_id) & (df_games['season'] == saison)]\n",
    "    elif lieu == 'exterieur':\n",
    "        matchs_du_club = df_games[(df_games['away_club_id'] == club_id) & (df_games['season'] == saison)]\n",
    "    else:\n",
    "        matchs_du_club = df_games[((df_games['home_club_id'] == club_id) | (df_games['away_club_id'] == club_id)) & (df_games['season'] == saison)]\n",
    "    \n",
    "    # Vérification du nombre de matchs\n",
    "    if len(matchs_du_club) < 5:\n",
    "        # Prendre les 10 derniers matchs toutes saisons confondues si moins de 5 matchs dans la saison\n",
    "        matchs_du_club = df_games[(df_games['home_club_id'] == club_id) | (df_games['away_club_id'] == club_id)]\n",
    "        matchs_du_club = matchs_du_club.sort_values(by='date', ascending=False).head(10)\n",
    "    else:\n",
    "        # Trier par date\n",
    "        matchs_du_club = matchs_du_club.sort_values(by='date', ascending=False)\n",
    "\n",
    "    # Ajout des informations supplémentaires\n",
    "    matchs_du_club['adversaire_id'] = matchs_du_club.apply(lambda row: row['away_club_id'] if row['home_club_id'] == club_id else row['home_club_id'], axis=1)\n",
    "    matchs_du_club['lieu'] = matchs_du_club.apply(lambda row: 'domicile' if row['home_club_id'] == club_id else 'exterieur', axis=1)\n",
    "    matchs_du_club['résultat'] = matchs_du_club.apply(lambda row: 'victoire' if (row['home_club_id'] == club_id and row['home_club_goals'] > row['away_club_goals']) or (row['away_club_id'] == club_id and row['away_club_goals'] > row['home_club_goals']) else 'défaite' if (row['home_club_id'] == club_id and row['home_club_goals'] < row['away_club_goals']) or (row['away_club_id'] == club_id and row['away_club_goals'] < row['home_club_goals']) else 'nul', axis=1)\n",
    "\n",
    "    return matchs_du_club[['date', 'season', 'home_club_id', 'away_club_id', 'adversaire_id', 'lieu', 'home_club_goals', 'away_club_goals', 'résultat']]\n",
    "\n",
    "def last_five_games(df_games, club_id, date, lieu='tous'):\n",
    "    \"\"\"\n",
    "    Récupère les 5 derniers matchs d'un club spécifié avant une date donnée en fonction du lieu du match.\n",
    "    \n",
    "    Paramètres:\n",
    "    df_games (DataFrame) : DataFrame des matchs.\n",
    "    club_id (int) : ID du club.\n",
    "    date (str ou pd.Timestamp) : Date avant laquelle les matchs doivent être récupérés.\n",
    "    lieu (str) : 'domicile', 'exterieur', ou 'tous' pour filtrer les matchs.\n",
    "    \n",
    "    Retourne:\n",
    "    DataFrame : Les matchs demandés avec les informations détaillées.\n",
    "    \"\"\"\n",
    "    # Assurer que la colonne 'date' est au format datetime\n",
    "    df_games['date'] = pd.to_datetime(df_games['date'])\n",
    "\n",
    "    # Filtrage des matchs avant la date donnée\n",
    "    matchs_du_club = df_games[df_games['date'] < date]\n",
    "    \n",
    "    if lieu == 'domicile':\n",
    "        matchs_du_club = matchs_du_club[matchs_du_club['home_club_id'] == club_id]\n",
    "    elif lieu == 'exterieur':\n",
    "        matchs_du_club = matchs_du_club[matchs_du_club['away_club_id'] == club_id]\n",
    "    else:  # 'tous'\n",
    "        matchs_du_club = matchs_du_club[(matchs_du_club['home_club_id'] == club_id) | (matchs_du_club['away_club_id'] == club_id)]\n",
    "    \n",
    "    # Tri des matchs par date et sélection des 5 derniers\n",
    "    matchs_du_club = matchs_du_club.sort_values(by='date', ascending=False).head(5)\n",
    "\n",
    "    # Ajout des informations supplémentaires\n",
    "    matchs_du_club['adversaire_id'] = matchs_du_club.apply(lambda row: row['away_club_id'] if row['home_club_id'] == club_id else row['home_club_id'], axis=1)\n",
    "    matchs_du_club['lieu'] = matchs_du_club.apply(lambda row: 'domicile' if row['home_club_id'] == club_id else 'exterieur', axis=1)\n",
    "    matchs_du_club['résultat'] = matchs_du_club.apply(lambda row: 'victoire' if (row['home_club_id'] == club_id and row['home_club_goals'] > row['away_club_goals']) or (row['away_club_id'] == club_id and row['away_club_goals'] > row['home_club_goals']) else 'défaite' if (row['home_club_id'] == club_id and row['home_club_goals'] < row['away_club_goals']) or (row['away_club_id'] == club_id and row['away_club_goals'] < row['home_club_goals']) else 'nul', axis=1)\n",
    "\n",
    "    return matchs_du_club[['date', 'home_club_id', 'away_club_id', 'adversaire_id', 'lieu', 'home_club_goals', 'away_club_goals', 'résultat']]\n",
    "    \n",
    "def last_game_id(df_games, club_id):\n",
    "    \"\"\"\n",
    "    Récupère l'ID du dernier match joué par un club spécifié.\n",
    "\n",
    "    Paramètres:\n",
    "    df_games (DataFrame) : DataFrame des matchs.\n",
    "    club_id (int) : ID du club.\n",
    "\n",
    "    Retourne:\n",
    "    int : ID du dernier match joué par le club.\n",
    "    \"\"\"\n",
    "    # Filtrer les matchs impliquant le club\n",
    "    matchs_du_club = df_games[(df_games['home_club_id'] == club_id) | (df_games['away_club_id'] == club_id)]\n",
    "    \n",
    "    # Trier par date en ordre décroissant et prendre le premier match\n",
    "    dernier_match = matchs_du_club.sort_values(by='date', ascending=False).iloc[0]\n",
    "\n",
    "    return dernier_match['game_id']\n",
    "\n",
    "def match_sheet(df_game_lineups, match_id, club_id):\n",
    "    \"\"\"\n",
    "    Récupère tous les player_id qui ont participé à un match spécifique pour un club donné.\n",
    "    \n",
    "    Paramètres:\n",
    "    df_game_lineups (DataFrame) : DataFrame des compositions d'équipe.\n",
    "    match_id (int) : ID du match.\n",
    "    club_id (int) : ID du club.\n",
    "    \n",
    "    Retourne:\n",
    "    Liste : Les identifiants (player_id) des joueurs qui ont participé au match.\n",
    "    \"\"\"\n",
    "    # Filtrer pour obtenir les lignes correspondant au match_id et club_id spécifiés\n",
    "    lineup_du_match = df_game_lineups[(df_game_lineups['game_id'] == match_id) & (df_game_lineups['club_id'] == club_id)]\n",
    "    \n",
    "    # Récupérer les player_id\n",
    "    joueurs = lineup_du_match['player_id'].tolist()\n",
    "\n",
    "    return joueurs\n",
    "\n",
    "def starting_lineup_match(df_game_lineups, match_id, club_id):\n",
    "    \"\"\"\n",
    "    Récupère les player_id des joueurs qui étaient dans la composition de départ d'un match spécifique pour un club donné.\n",
    "    \n",
    "    Paramètres:\n",
    "    df_game_lineups (DataFrame) : DataFrame des compositions d'équipe.\n",
    "    match_id (int) : ID du match.\n",
    "    club_id (int) : ID du club.\n",
    "    \n",
    "    Retourne:\n",
    "    Liste : Les identifiants (player_id) des joueurs de la composition de départ.\n",
    "    \"\"\"\n",
    "    #df_game_lineups = data_dict['game_lineups']\n",
    "    # Filtrer pour obtenir les lignes correspondant au match_id, club_id et type 'starting_lineup'\n",
    "    lineup_du_match = df_game_lineups[(df_game_lineups['game_id'] == match_id) & \n",
    "                                      (df_game_lineups['club_id'] == club_id) & \n",
    "                                      (df_game_lineups['type'] == 'starting_lineup')]\n",
    "    \n",
    "    # Récupérer les player_id\n",
    "    joueurs = lineup_du_match['player_id'].tolist()\n",
    "\n",
    "    return joueurs\n",
    "\n",
    "def market_value_player(df_player, player_id):\n",
    "    \"\"\"\n",
    "    Récupère la valeur marchande d'un joueur spécifié.\n",
    "    \n",
    "    Paramètres:\n",
    "    df_player_valuations (DataFrame) : DataFrame des évaluations des joueurs.\n",
    "    player_id (int) : ID du joueur.\n",
    "    \n",
    "    Retourne:\n",
    "    float : La valeur marchande du joueur en euros.\n",
    "    \"\"\"\n",
    "    # Trouver l'entrée correspondant au player_id\n",
    "    valeur_joueur = df_player[df_player['player_id'] == player_id]['market_value_in_eur']\n",
    "\n",
    "    # Retourner la valeur marchande, ou None si le joueur n'est pas trouvé\n",
    "    return valeur_joueur.iloc[0] if not valeur_joueur.empty else None\n",
    "\n",
    "def mean_team_value(df_player, liste_player_id):\n",
    "    \"\"\"\n",
    "    Calcule la valeur marchande moyenne d'une équipe.\n",
    "    \n",
    "    Paramètres:\n",
    "    df_player_valuations (DataFrame) : DataFrame des évaluations des joueurs.\n",
    "    liste_player_id (List[int]) : Liste des ID des joueurs.\n",
    "    \n",
    "    Retourne:\n",
    "    float : Valeur marchande moyenne de l'équipe.\n",
    "    \"\"\"\n",
    "    valeurs = [market_value_player(df_player, player_id) for player_id in liste_player_id]\n",
    "    valeurs = [v for v in valeurs if v is not None]  # Exclure les valeurs None\n",
    "    return sum(valeurs) / len(valeurs) if valeurs else 0\n",
    "\n",
    "def sum_team_value(df_player, liste_player_id):\n",
    "    \"\"\"\n",
    "    Calcule la somme des valeurs marchandes d'une équipe.\n",
    "    \n",
    "    Paramètres:\n",
    "    df_player_valuations (DataFrame) : DataFrame des évaluations des joueurs.\n",
    "    liste_player_id (List[int]) : Liste des ID des joueurs.\n",
    "    \n",
    "    Retourne:\n",
    "    float : Somme des valeurs marchandes de l'équipe.\n",
    "    \"\"\"\n",
    "    valeurs = [market_value_player(df_player, player_id) for player_id in liste_player_id]\n",
    "    valeurs = [v for v in valeurs if v is not None]  # Exclure les valeurs None\n",
    "    return sum(valeurs)\n",
    "\n",
    "def predire_resultat(model, match_features, scaler, seuil_nul=0.5):\n",
    "    \"\"\"\n",
    "    Prédit le résultat d'un match de football en utilisant un modèle de réseau de neurones entraîné.\n",
    "    \n",
    "    Paramètres :\n",
    "    model : Le modèle de réseau de neurones entraîné.\n",
    "    match_features : Un DataFrame contenant les caractéristiques du match.\n",
    "    scaler : L'objet StandardScaler utilisé pour normaliser les caractéristiques d'entraînement.\n",
    "    seuil_nul : Seuil de confiance pour prédire un match nul.\n",
    "    \n",
    "    Retourne :\n",
    "    str : La prédiction du résultat du match ('victoire', 'nul', 'défaite').\n",
    "    \"\"\"\n",
    "    # Normalisation des caractéristiques du match\n",
    "    match_features_scaled = scaler.transform(match_features)\n",
    "\n",
    "    # Faire la prédiction\n",
    "    prediction_prob = model.predict(match_features_scaled)\n",
    "    \n",
    "    # Obtenir l'indice de la classe avec la probabilité la plus élevée\n",
    "    predicted_class = np.argmax(prediction_prob, axis=1)[0]\n",
    "\n",
    "    # Ajuster la prédiction en fonction du seuil pour les matchs nuls\n",
    "    if prediction_prob[0][1] >= seuil_nul:  # Supposons que l'indice 1 représente les matchs nuls\n",
    "        resultat = \"nul\"\n",
    "    else:\n",
    "        resultat = \"victoire\" if predicted_class == 0 else \"defaite\"  # Supposons que l'indice 2 représente les victoires\n",
    "\n",
    "    return resultat\n",
    "\n",
    "\n",
    "def get_name(club_id):\n",
    "    \"\"\"\n",
    "    Renvoie le nom du club de football basé sur son identifiant.\n",
    "\n",
    "    Paramètres:\n",
    "    club_id (int): L'identifiant du club.\n",
    "\n",
    "    Retourne:\n",
    "    str: Le nom du club.\n",
    "    \"\"\"\n",
    "    # Trouver la ligne correspondante au club_id\n",
    "    club_info = df_clubs[df_clubs['club_id'] == club_id]\n",
    "\n",
    "    # Renvoie le nom du club s'il est trouvé, sinon renvoie None\n",
    "    if not club_info.empty:\n",
    "        return club_info['name'].iloc[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def calculer_forme(df_games, club_id, date_du_match, lieu='tous'):\n",
    "    \"\"\"\n",
    "    Calcule la forme d'un club sur ses 5 derniers matchs avant la date du match spécifiée.\n",
    "    \n",
    "    Paramètres:\n",
    "    df_games (DataFrame) : DataFrame des matchs.\n",
    "    club_id (int) : ID du club.\n",
    "    date_du_match (str ou pd.Timestamp) : Date du match pour lequel la forme est calculée.\n",
    "    lieu (str) : 'domicile', 'exterieur', ou 'tous' pour filtrer les matchs.\n",
    "    \n",
    "    Retourne:\n",
    "    int : Les points accumulés par le club sur ses 5 derniers matchs.\n",
    "    \"\"\"\n",
    "    # Assurer que la colonne 'date' est au format datetime\n",
    "    #df_games['date'] = pd.to_datetime(df_games['date'])\n",
    "\n",
    "    # Filtrer les matchs précédents et trier par date\n",
    "    matchs_precedents = last_five_games(df_games, club_id, date_du_match, lieu)\n",
    "    \n",
    "    # Calculer les points (exemple simplifié)\n",
    "    points = 0\n",
    "    for _, row in matchs_precedents.iterrows():\n",
    "        if row['home_club_id'] == club_id:\n",
    "            points += 3 if row['home_club_goals'] > row['away_club_goals'] else 1 if row['home_club_goals'] == row['away_club_goals'] else 0\n",
    "        else:\n",
    "            points += 3 if row['away_club_goals'] > row['home_club_goals'] else 1 if row['away_club_goals'] == row['home_club_goals'] else 0\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3cc0ca5-f5de-481f-8e73-aa90d53e32de",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'df_final.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m df_to_train_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_to_train.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Charger le fichier Excel dans un DataFrame\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df_final \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_final_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m df_final\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1580\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m   1578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[1;32m-> 1580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1584\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:553\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03mReader using openpyxl engine.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;124;03m    Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    552\u001b[0m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 553\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:572\u001b[0m, in \u001b[0;36mBaseExcelReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m    569\u001b[0m     handle\u001b[38;5;241m=\u001b[39mfilepath_or_buffer, compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m    570\u001b[0m )\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, (ExcelFile, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workbook_class)):\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workbook_class):\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df_final.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_final_path = \"df_final.xlsx\"\n",
    "df_to_train_path = \"df_to_train.xlsx\"\n",
    "\n",
    "# Charger le fichier Excel dans un DataFrame\n",
    "df_final = pd.read_excel(df_final_path, engine='openpyxl')\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e846a-8bf4-4516-8358-8cf13df94395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_train = pd.read_excel(df_to_train_path, engine='openpyxl')\n",
    "conditions = (\n",
    "    (df_final['home_team_market_value'] >= 1) & \n",
    "    (df_final['away_team_market_value'] >= 1) & \n",
    "    (df_final['home_team_form'] >= 1) & \n",
    "    (df_final['away_team_form'] >= 1)\n",
    ")\n",
    "df_to_train = df_final[conditions]\n",
    "df_to_train = df_to_train.drop([\"season\", \"game_id\", \"away_club_position\", \"home_club_position\", \"date\"], axis=1).dropna()\n",
    "\n",
    "df_to_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8290692d-6743-447c-ba89-16f255c1ba03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du df 33640\n",
      "Nombre de lignes avec 0 dans 'resultat': 8349\n",
      "Nombre de lignes avec -1 dans 'resultat': 10326\n",
      "Nombre de lignes avec 1 dans 'resultat': 14965\n",
      "PB home market value: 0\n",
      "PB away market value: 0\n",
      "PB home market value: 0\n",
      "PB away market value: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Taille du df {len(df_to_train)}\")\n",
    "print(\"Nombre de lignes avec 0 dans 'resultat':\", (df_to_train['resultat'] == 0).sum())\n",
    "print(\"Nombre de lignes avec -1 dans 'resultat':\", (df_to_train['resultat'] == -1).sum())\n",
    "print(\"Nombre de lignes avec 1 dans 'resultat':\", (df_to_train['resultat'] == 1).sum())\n",
    "print(\"PB home market value:\", (df_to_train['home_team_market_value'] < 1).sum())\n",
    "print(\"PB away market value:\", (df_to_train['away_team_market_value'] < 1).sum())\n",
    "print(\"PB home market value:\", (df_to_train['home_team_form'] < 1).sum())\n",
    "print(\"PB away market value:\",  (df_to_train['away_team_form'] < 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48845db7-89b8-4809-a837-4dfa0ac6065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "673/673 [==============================] - 3s 3ms/step - loss: 1.7574 - accuracy: 0.4221 - val_loss: 1.1331 - val_accuracy: 0.4195\n",
      "Epoch 2/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.7104 - accuracy: 0.4434 - val_loss: 1.0776 - val_accuracy: 0.4458\n",
      "Epoch 3/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6932 - accuracy: 0.4448 - val_loss: 1.0910 - val_accuracy: 0.4525\n",
      "Epoch 4/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6839 - accuracy: 0.4435 - val_loss: 1.0798 - val_accuracy: 0.4380\n",
      "Epoch 5/50\n",
      "673/673 [==============================] - 1s 2ms/step - loss: 1.6778 - accuracy: 0.4434 - val_loss: 1.0946 - val_accuracy: 0.4442\n",
      "Epoch 6/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6756 - accuracy: 0.4474 - val_loss: 1.0691 - val_accuracy: 0.4341\n",
      "Epoch 7/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6725 - accuracy: 0.4470 - val_loss: 1.0683 - val_accuracy: 0.4442\n",
      "Epoch 8/50\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 1.6716 - accuracy: 0.4469 - val_loss: 1.0725 - val_accuracy: 0.4553\n",
      "Epoch 9/50\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 1.6721 - accuracy: 0.4481 - val_loss: 1.0710 - val_accuracy: 0.4399\n",
      "Epoch 10/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6702 - accuracy: 0.4485 - val_loss: 1.0666 - val_accuracy: 0.4423\n",
      "Epoch 11/50\n",
      "673/673 [==============================] - 1s 2ms/step - loss: 1.6699 - accuracy: 0.4487 - val_loss: 1.0622 - val_accuracy: 0.4399\n",
      "Epoch 12/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6686 - accuracy: 0.4472 - val_loss: 1.0610 - val_accuracy: 0.4520\n",
      "Epoch 13/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6689 - accuracy: 0.4477 - val_loss: 1.0437 - val_accuracy: 0.4603\n",
      "Epoch 14/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6680 - accuracy: 0.4500 - val_loss: 1.0645 - val_accuracy: 0.4414\n",
      "Epoch 15/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6688 - accuracy: 0.4483 - val_loss: 1.0571 - val_accuracy: 0.4395\n",
      "Epoch 16/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6685 - accuracy: 0.4425 - val_loss: 1.0654 - val_accuracy: 0.4325\n",
      "Epoch 17/50\n",
      "673/673 [==============================] - 2s 3ms/step - loss: 1.6675 - accuracy: 0.4433 - val_loss: 1.0439 - val_accuracy: 0.4550\n",
      "Epoch 18/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6679 - accuracy: 0.4500 - val_loss: 1.0798 - val_accuracy: 0.4267\n",
      "Epoch 19/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6676 - accuracy: 0.4460 - val_loss: 1.0578 - val_accuracy: 0.4527\n",
      "Epoch 20/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6675 - accuracy: 0.4483 - val_loss: 1.0531 - val_accuracy: 0.4550\n",
      "Epoch 21/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6685 - accuracy: 0.4474 - val_loss: 1.0631 - val_accuracy: 0.4460\n",
      "Epoch 22/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6672 - accuracy: 0.4470 - val_loss: 1.0721 - val_accuracy: 0.4421\n",
      "Epoch 23/50\n",
      "673/673 [==============================] - 2s 2ms/step - loss: 1.6679 - accuracy: 0.4435 - val_loss: 1.0517 - val_accuracy: 0.4576\n",
      "211/211 [==============================] - 0s 1ms/step - loss: 1.0482 - accuracy: 0.4688\n",
      "Loss: 1.0482455492019653, Accuracy: 0.46878716349601746\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Supposons que df_final est déjà défini et contient les données nécessaires\n",
    "\n",
    "# 1. Préparation et nettoyage des données\n",
    "conditions = (\n",
    "    (df_final['home_team_market_value'] >= 1) & \n",
    "    (df_final['away_team_market_value'] >= 1) & \n",
    "    (df_final['home_team_form'] >= 1) & \n",
    "    (df_final['away_team_form'] >= 1)\n",
    ")\n",
    "df_to_train = df_final[conditions]\n",
    "df_to_train = df_to_train.drop([\"season\", \"game_id\", \"away_club_position\", \"home_club_position\", \"date\"], axis=1).dropna()\n",
    "\n",
    "X = df_to_train.drop([\"resultat\"], axis=1)\n",
    "y = df_to_train[\"resultat\"]\n",
    "\n",
    "# Pas de rééquilibrage des classes avec SMOTE ou UnderSampler ici\n",
    "\n",
    "y_encoded = to_categorical(y, num_classes=3)\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisation des caractéristiques\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. Construction et entraînement du modèle\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Calcul des poids des classes\n",
    "# Supposons que dans votre encodage, la classe 0 correspond aux matchs nuls,\n",
    "# 1 correspond aux défaites, et 2 correspond aux victoires à domicile\n",
    "\n",
    "# Poids des classes personnalisés\n",
    "# Augmentez ces valeurs pour augmenter l'importance de la victoire et de la défaite dans l'entraînement\n",
    "poids_victoire = 2.25\n",
    "poids_defaite = 2.0\n",
    "poids_nul = 1.0  # Diminuez cette valeur pour diminuer l'importance des matchs nuls\n",
    "\n",
    "# Créez un dictionnaire de poids\n",
    "class_weights_custom = {\n",
    "    0: poids_victoire,   # Match nul\n",
    "    1: poids_nul,  # Défaite\n",
    "    2: poids_defaite  # Victoire\n",
    "}\n",
    "\n",
    "# Entraînement avec les poids des classes\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train_encoded, \n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weights_custom,  # Utilisation des poids des classes\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4. Évaluation du modèle\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test_encoded)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "588aea4d-9925-4fc8-b485-c83ec8c48aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras.layers import LSTM\\n\\nmodel = Sequential()\\nmodel.add(LSTM(50, activation='relu', input_shape=(X_train_scaled.shape[1], 1)))\\nmodel.add(Dense(3, activation='softmax'))\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train_scaled.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train_scaled.shape[1], 1)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5d48a32-5c8f-446e-a03c-6585d8e492e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "Résultat prédit pour le match entre les clubs Toulouse Football Club et Lille Olympique Sporting Club Lille Métropole : victoire\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Résultat prédit pour le match entre les clubs Racing Club de Strasbourg Alsace et Paris Saint-Germain Football Club : defaite\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Résultat prédit pour le match entre les clubs Stade de Reims et Association sportive de Monaco Football Club : victoire\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Résultat prédit pour le match entre les clubs Football Club Lorient-Bretagne Sud et Olympique Lyonnais : victoire\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Résultat prédit pour le match entre les clubs Olympique Gymnaste Club Nice Côte d'Azur et Racing Club de Lens : nul\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Résultat prédit pour le match entre les clubs Football Club de Nantes et Olympique de Marseille : victoire\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Résultat prédit pour le match entre les clubs Le Havre Athletic Club et Stade Rennais Football Club : defaite\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Résultat prédit pour le match entre les clubs Stade brestois 29 et Montpellier Hérault Sport Club : victoire\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Résultat prédit pour le match entre les clubs Football Club de Metz et Clermont Foot 63 : victoire\n"
     ]
    }
   ],
   "source": [
    "df_clubs = data_dict[\"clubs\"]\n",
    "df_players = data_dict['players']\n",
    "df_games = data_dict['games']\n",
    "df_game_lineups = data_dict['game_lineups']\n",
    "\n",
    "# Liste des matchs pour lesquels faire des prédictions\n",
    "#liste_matchs = [(1041, 583), (1041, 3524), (583, 3524), (1041, 162), (162, 1041), \n",
    "#                (418, 3302), (418, 12321), (31, 281), (281, 31), (418, 281), (281, 418), (281, 281)]\n",
    "import random\n",
    "\n",
    "# Liste des identifiants de club\n",
    "club_ids = [\n",
    "    162, 244, 273, 347, 415, 417, 583, 667, 738, 826,\n",
    "    969, 995, 1041, 1082, 1158, 1421, 3524, 3911\n",
    "]\n",
    "\n",
    "# Générer des paires aléatoires de matchs\n",
    "liste_matchs = []\n",
    "\n",
    "while len(club_ids) > 1:  # Continue tant qu'il y a au moins 2 clubs pour former un match\n",
    "    home = random.choice(club_ids)\n",
    "    club_ids.remove(home)\n",
    "    away = random.choice(club_ids)\n",
    "    club_ids.remove(away)\n",
    "    liste_matchs.append((home, away))\n",
    "\n",
    "# Boucle sur chaque match pour faire des prédictions\n",
    "for home_club_id, away_club_id in liste_matchs:\n",
    "    match_features = pd.DataFrame({\n",
    "        'home_club_id': [home_club_id],\n",
    "        'away_club_id': [away_club_id],\n",
    "        'home_team_market_value': [mean_team_value(df_players, starting_lineup_match(df_game_lineups, last_game_id(df_games, home_club_id), home_club_id))],\n",
    "        'away_team_market_value': [mean_team_value(df_players, starting_lineup_match(df_game_lineups, last_game_id(df_games, away_club_id), away_club_id))],\n",
    "        'home_team_form': [calculer_forme(df_games, home_club_id, \"2024-01-01\", \"domicile\")],\n",
    "        'away_team_form': [calculer_forme(df_games, away_club_id, \"2024-01-01\", \"exterieur\")]\n",
    "    })\n",
    "\n",
    "    # Faire la prédiction pour le match courant\n",
    "    resultat_predit = predire_resultat(model, match_features, scaler, 0.4)\n",
    "    print(f\"Résultat prédit pour le match entre les clubs {get_name(home_club_id)} et {get_name(away_club_id)} : {resultat_predit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7768a7f-c308-4941-a674-73c40e4f22f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_sequential.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Supposons que `model` est votre modèle entraîné\n",
    "joblib.dump(model, 'model_sequential.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65208336-5da3-43a5-bcd7-8929f9dfc1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_sequential.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Supposons que `model` est votre modèle entraîné\n",
    "joblib.dump(scaler, 'scaler_sequential.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
